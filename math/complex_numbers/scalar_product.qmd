---
title: Scalar Product
subtitle: Vectors and Functions
toc: true
format:
    html:
        html-math-method: katex
        self-contained: true
        monofont: JetBrains Mono
        code-overflow: wrap
        code-tools: true
        code-link: true
format-links: true
jupyter: python3
---

# Introduction

Here comes the introduction

# Definitions

## Finite-Dimensional Vector Space

A **scalar product** on $\mathbb{R}^n$ is a function $\langle \cdot, \cdot \rangle: \mathbb{R}^n \times \mathbb{R}^n \to \mathbb{R}$ that satisfies the following properties:

1. **Symmetry**: $\langle u, v \rangle = \langle v, u \rangle$ for all $u, v \in \mathbb{R}^n$.
2. **Linearity**:
    - $\langle u, v + w \rangle = \langle u, v \rangle + \langle u, w \rangle$ for all $u, v, w \in \mathbb{R}^n$.
    - $\langle u, \lambda v \rangle = \lambda \langle u, v \rangle$ for all $u, v \in \mathbb{R}^n$ and $\lambda \in \mathbb{R}$.
3. **Positive Definiteness**: $\langle u, u \rangle \geq 0$ for all $u \in $\mathbb{R}^n$ and $\langle u, u \rangle = 0$ if and only if $u = 0$.

### Example: Dot Product

The **dot product** is a scalar product on $\mathbb{R}^n$ defined by $\langle u, v \rangle = u \cdot v = \sum_{i=1}^n u_i v_i$ for all $u, v \in \mathbb{R}^n$.

::: {.callout-note}
In $\mathbb{R}^2$, the dot product of two vectors $u = (u_1, u_2)$ and $v = (v_1, v_2)$ is given by 

$$
u \cdot v = u_1 v_1 + u_2 v_2.
$$

:::

The properties of the dot product satisfy the properties of a scalar product:

1. **Symmetry**: $u \cdot v = v \cdot u$.

    **Proof**: $u \cdot v = \sum_{i=1}^n u_i v_i = \sum_{i=1}^n v_i u_i = v \cdot u$.
2. **Linearity**:
    - $u \cdot (v + w) = \sum_{i=1}^n u_i (v_i + w_i) = \sum_{i=1}^n u_i v_i + \sum_{i=1}^n u_i w_i = u \cdot v + u \cdot w$.
    - $u \cdot (\lambda v) = \sum_{i=1}^n u_i (\lambda v_i) = \lambda \sum_{i=1}^n u_i v_i = \lambda u \cdot v$.
3. **Positive Definiteness**:
    - $u \cdot u = \sum_{i=1}^n u_i^2 \geq 0$.
    - $u \cdot u = 0$ if and only if $u = 0$.

## Infinite-Dimensional Vector Space

A **scalar product** on a vector space $V$ is a function $\langle \cdot, \cdot \rangle: V \times V \to \mathbb{R}$ that satisfies the following properties:

1. **Symmetry**: $\langle u, v \rangle = \langle v, u \rangle$ for all $u, v \in V$.
2. **Linearity**:
    - $\langle u, v + w \rangle = \langle u, v \rangle + \langle u, w \rangle$ for all $u, v, w \in V$.
    - $\langle u, \lambda v \rangle = \lambda \langle u, v \rangle$ for all $u, v \in V$ and $\lambda \in \mathbb{R}$.
3. **Positive Definiteness**: $\langle u, u \rangle \geq 0$ for all $u \in V$ and $\langle u, u \rangle = 0$ if and only if $u = 0$.

### Example: Function Space

Let $V = C([a, b])$ be the vector space of continuous functions on the interval $[a, b]$. The **inner product** on $V$ is defined by

$$
\langle f, g \rangle = \int_a^b f(x) g(x) \, dx
$$

The properties of the inner product satisfy the properties of a scalar product:

1. **Symmetry**: $\langle f, g \rangle = \int_a^b f(x) g(x) \, dx = \int_a^b g(x) f(x) \, dx = \langle g, f \rangle$.
2. **Linearity**:
    - $\langle f, g + h \rangle = \int_a^b f(x) (g(x) + h(x)) \, dx = \int_a^b f(x) g(x) \, dx + \int_a^b f(x) h(x) \, dx = \langle f, g \rangle + \langle f, h \rangle$.
    - $\langle f, \lambda g \rangle = \int_a^b f(x) (\lambda g(x)) \, dx = \lambda \int_a^b f(x) g(x) \, dx = \lambda \langle f, g \rangle$.
3. **Positive Definiteness**:
    - $\langle f, f \rangle = \int_a^b f^2(x) \, dx \geq 0$.
    - $\langle f, f \rangle = 0$ if and only if $f = 0$.

# Basis

## Finite-Dimensional Vector Space

Let $V$ be a finite-dimensional vector space with a scalar product $\langle \cdot, \cdot \rangle$. A **basis** for $V$ is a set of vectors $\{v_1, v_2, \ldots, v_n\}$ such that every vector $v \in V$ can be written as a linear combination of the basis vectors:

$$
v = \sum_{i=1}^n \alpha_i v_i
$$

where $\alpha_i \in \mathbb{R}$ are the coefficients of the linear combination and at least one of the coefficients is nonzero: $\exists i \in \{1, 2, \ldots, n\}$ such that $\alpha_i \neq 0$.

The basis is **orthonormal** if the basis vectors are orthogonal to each other and have unit length:

$$
\langle v_i, v_j \rangle = \delta_{ij}
$$

where $\delta_{ij}$ is the Kronecker delta:

- $\delta_{ij} = 1$ if $i = j$.
- $\delta_{ij} = 0$ if $i \neq j$.

### Example: Standard Basis in $\mathbb{R}^n$

The **standard basis** in $\mathbb{R}^n$ is the set of vectors $\{e_1, e_2, \ldots, e_n\}$ where $e_i$ is the $i$-th unit vector:

$$
e_i = (0, 0, \ldots, 1, \ldots, 0)
$$

where the $1$ is in the $i$-th position.

### Example: Standard Basis in $\mathbb{R}^2$

The **standard basis** in $\mathbb{R}^2$ is the set of vectors $\{e_1, e_2\}$ where

$$
e_1 = (1, 0) \quad \text{and} \quad e_2 = (0, 1)
$$

The standard basis is orthonormal because

$$
\langle e_1, e_1 \rangle = e_1 \cdot e_1 = 1 \quad \text{and} \quad \langle e_1, e_2 \rangle = e_1 \cdot e_2 = 0
$$

## Infinite-Dimensional Vector Space

Let $V$ be an infinite-dimensional vector space with a scalar product $\langle \cdot, \cdot \rangle$. A **basis** for $V$ is a set of vectors (functions) $\{v_1, v_2, \ldots\}$ such that every vector $v \in V$ can be written as an infinite linear combination of the basis vectors:

$$
v = \sum_{i=1}^\infty \alpha_i v_i
$$

where $\alpha_i \in \mathbb{R}$ are the coefficients of the linear combination and at least one of the coefficients is nonzero: $\exists i \in \mathbb{N}$ such that $\alpha_i \neq 0$.

::: {.callout-caution}
Sometimes, the first index of the basis vectors is $0$ instead of $1$.
:::

The basis is **orthonormal** if the basis vectors are orthogonal to each other and have unit length:

$$
\langle v_i, v_j \rangle = \delta_{ij}
$$

where $\delta_{ij}$ is the Kronecker delta:

- $\delta_{ij} = 1$ if $i = j$.
- $\delta_{ij} = 0$ if $i \neq j$.

### Example: Fourier Basis

The **Fourier basis** in $C^\infty([-\pi, \pi])$[^1] is composed from the set of functions $\{\sin(nx)\}$ and $\{\cos(nx)\}$ for $n = 0, 1, 2, \ldots$.

[^1]: The space of infinitely differentiable functions on the interval $[-\pi, \pi]$.

This set of functions is orthogonal. To show this, we need to compute the inner product of different sine and cosine functions and their interactions:

1. Different sine functions:
    1. Assume that $n \neq m$ and, without loss of generality, $m < n$.
        $$
        \langle \sin(nx), \sin(mx) \rangle = \int_{-\pi}^\pi \sin(nx) \sin(mx) \, dx =\\
        \int_{-\pi}^\pi \frac{1}{2} \left( \cos((n-m)x) - \cos((n+m)x) \right) \, dx =\\
        \frac{1}{2} \left( \int_{-\pi}^\pi \cos((n-m)x) \, dx - \int_{-\pi}^\pi \cos((n+m)x) \, dx \right) =\\
        \frac{1}{2} \left( \frac{1}{n-m} \sin((n-m)x) \Big|_{-\pi}^\pi - \frac{1}{n+m} \sin((n+m)x) \Big|_{-\pi}^\pi \right) =\\
        \frac{1}{2} \left( 0 - 0 - (0 - 0) \right) = 0.
        $$

        The last equality holds because $n$ and $m$ are integers and, therefore, $\sin((n \pm m) \pi) = 0$.

        Here, we use the [trigonometric identity](https://ru.wikipedia.org/wiki/%D0%A2%D1%80%D0%B8%D0%B3%D0%BE%D0%BD%D0%BE%D0%BC%D0%B5%D1%82%D1%80%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D0%B5_%D1%84%D1%83%D0%BD%D0%BA%D1%86%D0%B8%D0%B8#%D0%9F%D1%80%D0%BE%D0%B8%D0%B7%D0%B2%D0%B5%D0%B4%D0%B5%D0%BD%D0%B8%D1%8F):
        
        $$
        \sin(a) \sin(b) = \frac{1}{2} \left( \cos(a-b) - \cos(a+b) \right).
        $$
    2. Assume that $n = m$.

        $$
        \langle \sin(nx), \sin(nx) \rangle = \int_{-\pi}^\pi \sin^2(nx) \, dx =\\
        \int_{-\pi}^\pi \frac{1 - \cos(2nx)}{2} \, dx =\\
        \frac{1}{2} \left( \int_{-\pi}^\pi 1 \, dx - \int_{-\pi}^\pi \cos(2nx) \, dx \right) =\\
        \frac{1}{2} \left( x \Big|_{-\pi}^\pi - \frac{1}{2n} \sin(2nx) \Big|_{-\pi}^\pi \right) =\\
        \frac{1}{2} \left( \pi - (-\pi) - (0 - 0) \right) = \pi.
        $$

        Here, we found that the the squared norm of the sine functions in the basis is $\pi$.

2. Different cosine functions, in the same way, are orthogonal for $n \neq m$:

    $$
    \langle \cos(nx), \cos(mx) \rangle = \delta_{nm} \pi.
    $$

    If $n = m = 0$, then the scalar product is $2\pi$.

3. Sine and cosine functions are orthogonal:
    1. If $n\neq m$:

        $$
        \langle \sin(nx), \cos(mx) \rangle = \int_{-\pi}^\pi \sin(nx) \cos(mx) \, dx =\\
        \int_{-\pi}^\pi \frac{1}{2} \left( \sin((n+m)x) + \sin((n-m)x) \right) \, dx =\\
        \frac{1}{2} \left( \int_{-\pi}^\pi \sin((n+m)x) \, dx + \int_{-\pi}^\pi \sin((n-m)x) \, dx \right) =\\
        \frac{1}{2} \left( -\frac{1}{n+m} \cos((n+m)x) \Big|_{-\pi}^\pi - \frac{1}{n-m} \cos((n-m)x) \Big|_{-\pi}^\pi \right) =\\
        \frac{1}{2} \left( 0 - 0 - (0 - 0) \right) = 0.
        $$

    2. If $n = m$:

        $$
        \langle \sin(nx), \cos(nx) \rangle = \int_{-\pi}^\pi \sin(nx) \cos(nx) \, dx =\\
        \int_{-\pi}^\pi \frac{1}{2} \sin(2nx) \, dx = 0.
        $$

To construct an **orthonormal basis**, we need to normalize the basis vectors:

- For the sine functions, we divide each function by $\sqrt{\pi}$.
- For the cosine functions, we divide
    - the constant function by $\sqrt{2\pi}$,
    - the rest of the functions by $\sqrt{\pi}$.

Therefore, the orthonormal basis is

$$
\left\{ \frac{1}{\sqrt{2\pi}}, \frac{1}{\sqrt{\pi}} \sin(x), \frac{1}{\sqrt{\pi}} \cos(x), \frac{1}{\sqrt{\pi}} \sin(2x), \frac{1}{\sqrt{\pi}} \cos(2x), \ldots \right\}
$$

## Practical Examples

### Example: Scalar Product in $\mathbb{R}^2$

Let $u = (1, 2)$ be a vector in $\mathbb{R}^2$. We will use the standard basis $\{e_1, e_2\}$ to compute the scalar product of $u$ with the basis vectors:

- Scalar product with $e_1$:

    $$
    u \cdot e_1 = (1, 2) \cdot (1, 0) = 1 \cdot 1 + 2 \cdot 0 = 1
    $$

- Scalar product with $e_2$:

    $$
    u \cdot e_2 = (1, 2) \cdot (0, 1) = 1 \cdot 0 + 2 \cdot 1 = 2
    $$

Therefore, the vector $u$ can be written as a linear combination of the basis vectors:

$$
u = 1 \cdot (1, 0) + 2 \cdot (0, 1) = e_1 + 2 e_2
$$

```{python}
import numpy as np
import matplotlib.pyplot as plt

# Define the vector u
u = np.array([1, 2])

# Define the basis vectors
e1 = np.array([1, 0])
e2 = np.array([0, 1])

# Compute the scalar products
u_dot_e1 = np.dot(u, e1)
u_dot_e2 = np.dot(u, e2)

# Compute the linear combination
v = u_dot_e1 * e1 + u_dot_e2 * e2

# Plot the vectors
plt.figure(figsize=(5, 5))
plt.quiver(0, 0, u[0], u[1], angles='xy', scale_units='xy', scale=1, color='r', label='u')
plt.quiver(0, 0, e1[0], e1[1], angles='xy', scale_units='xy', scale=1, color='b', label='e1')
plt.quiver(0, 0, e2[0], e2[1], angles='xy', scale_units='xy', scale=1, color='g', label='e2')
plt.quiver(0, 0, v[0], v[1], angles='xy', scale_units='xy', scale=1, color='y', label='v')
plt.xlim(-1, 3)
plt.ylim(-1, 3)
plt.gca().set_aspect('equal', adjustable='box')
plt.legend()
plt.grid()
plt.show()
```

### Example: Scalar Product in $C^\infty([-\pi, \pi])$

Let $f(x) = \sin(x) + \cos(x)$ in $C^\infty([-\pi,\pi])$. 

#### 1. General form of the expansion

Any $f \in L^2(-\pi,\pi)$ can be written as
$$
f(x) 
= \frac{a_0}{\sqrt{2\pi}} 
+ \sum_{n=1}^{\infty} \Bigl( \frac{b_n}{\sqrt{\pi}} \sin(nx) + \frac{a_n}{\sqrt{\pi}} \cos(nx) \Bigr).
$$
The coefficients are
$$
a_0 = \int_{-\pi}^\pi f(x)\,\frac{1}{\sqrt{2\pi}}\,dx, 
\quad
b_n = \int_{-\pi}^\pi f(x)\,\frac{1}{\sqrt{\pi}}\sin(nx)\,dx, 
\quad
a_n = \int_{-\pi}^\pi f(x)\,\frac{1}{\sqrt{\pi}}\cos(nx)\,dx.
$$

#### 2. Compute the constant term $a_0$

$$
a_0 
= \int_{-\pi}^\pi \bigl(\sin(x) + \cos(x)\bigr)\,\frac{1}{\sqrt{2\pi}}\,dx
= \frac{1}{\sqrt{2\pi}} 
\Bigl(\int_{-\pi}^\pi \sin(x)\,dx + \int_{-\pi}^\pi \cos(x)\,dx\Bigr).
$$
Both integrals vanish, so \(a_0 = 0\).

#### 3. Compute the sine coefficients $b_n$

$$
b_n
= \int_{-\pi}^\pi \bigl(\sin(x) + \cos(x)\bigr) \frac{1}{\sqrt{\pi}}\sin(nx)\,dx.
$$
Using standard orthogonality, 
$$
b_1 = \sqrt{\pi}, 
\quad 
b_n = 0\ (n \neq 1).
$$

#### 4. Compute the cosine coefficients $a_n$

$$
a_n
= \int_{-\pi}^\pi \bigl(\sin(x) + \cos(x)\bigr) \frac{1}{\sqrt{\pi}}\cos(nx)\,dx.
$$
Again, by orthogonality,
$$
a_1 = \sqrt{\pi}, 
\quad
a_n = 0\ (n \neq 1).
$$

#### 5. Final decomposition

Putting these together:
$$
f(x) 
= 0 \cdot \frac{1}{\sqrt{2\pi}}
+ \sum_{n=1}^{\infty} \Bigl( b_n \,\frac{1}{\sqrt{\pi}}\sin(nx) + a_n \,\frac{1}{\sqrt{\pi}}\cos(nx) \Bigr)
= \sin(x) + \cos(x).
$$
Hence the only non-zero coefficients are $a_1 = \sqrt{\pi}$ and $b_1 = \sqrt{\pi}$.

```{python}
import numpy as np
import matplotlib.pyplot as plt

# Define the function f(x)
f = lambda x: np.sin(x) + np.cos(x)

# Define the basis functions
a0 = 0
b1 = np.sqrt(np.pi)
a1 = np.sqrt(np.pi)

x = np.linspace(-np.pi, np.pi, 1000)

# Compute the linear combination
v = a0 / np.sqrt(2 * np.pi) + b1 / np.sqrt(np.pi) * np.sin(x) + a1 / np.sqrt(np.pi) * np.cos(x)

# Plot the function
plt.figure(figsize=(5, 5))
plt.plot(x, f(x), 'r', label='f(x)')
plt.plot(x, v, 'b--', label='v(x)')
plt.legend()
plt.grid()
plt.show()
```
