---
title: "Newton's Method"
author: "Professor Alex"
date: "2025-05-16"
format:
  html:
    toc: true
    toc-depth: 3
    embed-resources: true
    code-fold: true
    monofont: JetBrains Mono
    highlight-style: atom-one
jupyter: python3
---

## Introduction

Newton's method is an iterative method for finding the roots of a differentiable function. It is also known as the Newton-Raphson method. The method is based on the idea that a continuous and differentiable function can be approximated by a straight line tangent to it. The tangent line is then extended to the x-axis to find a better approximation of the root.

## The Algorithm

Given a function $f(x)$, the Newton method is defined as follows:

1. Choose an initial guess $x_0$ for the root.
2. Compute the tangent line to the function at $x_0$.
3. Find the x-intercept of the tangent line to get the next approximation $x_1$.
4. Repeat steps 2 and 3 until the desired accuracy is achieved.

The formula for the Newton method is given by:

$$
x_{n+1} = x_n - \frac{f(x_n)}{f'(x_n)}
$$

where $f'(x)$ is the derivative of the function $f(x)$.

### The Geometric Interpretation

The formula can be derived from the equation of the tangent line at the point $(x_n, f(x_n))$:

$$
y - f(x_n) = f'(x_n)(x - x_n)
$$

To find the x-intercept (where y = 0), we set $y = 0$ and solve for $x$:

$$
0 - f(x_n) = f'(x_n)(x - x_n)
$$

$$
-f(x_n) = f'(x_n)(x - x_n)
$$

$$
-\frac{f(x_n)}{f'(x_n)} = x - x_n
$$

$$
x = x_n - \frac{f(x_n)}{f'(x_n)}
$$

This gives us the formula for Newton's method.

```{python}
#| label: fig-newton-method
#| fig-cap: "Visualization of Newton's Method"
import numpy as np
import matplotlib.pyplot as plt

# Define the function and its derivative
def f(x):
    return x**2 - 4

def f_prime(x):
    return 2*x

# Initial guess
x0 = 1
iterations = 3

# Create plotting points
x_vals = np.linspace(-1, 3, 1000)
y_vals = f(x_vals)

# Create the figure
plt.figure(figsize=(10, 6))
plt.plot(x_vals, y_vals, 'b-', label='f(x) = x^2 - 4')
plt.axhline(y=0, color='k', linestyle='-', alpha=0.3)
plt.axvline(x=0, color='k', linestyle='-', alpha=0.3)
plt.grid(True, linestyle='--', alpha=0.7)

# Mark the real root
plt.plot(2, 0, 'go', markersize=8, label='Actual root (x=2)')

# Perform Newton's method iterations
x = x0
colors = ['r', 'g', 'purple']

x_points = [x]

for i in range(iterations):
    # Compute next value
    fx = f(x)
    fpx = f_prime(x)
    x_new = x - fx / fpx
    
    # Plot the tangent line
    tangent_x = np.linspace(x-0.5, x+0.5, 100)
    tangent_y = fpx * (tangent_x - x) + fx
    plt.plot(tangent_x, tangent_y, color=colors[i], linestyle='--', 
             label=f'Tangent at x{i}={x:.4f}')
    
    # Plot the point and its projection
    plt.plot(x, fx, color=colors[i], marker='o')
    plt.plot([x, x], [0, fx], color=colors[i], linestyle=':')
    plt.plot([x, x_new], [fx, 0], color=colors[i], linestyle=':')
    plt.plot([x_new], [0], color=colors[i], marker='o')
    
    # Update x for next iteration
    x = x_new
    x_points.append(x)

# Add annotations for each point
for i, point in enumerate(x_points):
    plt.annotate(f'$x_{i}$ = {point:.4f}', 
                 xy=(point, 0), 
                 xytext=(point, -1),
                 ha='center',
                 arrowprops=dict(arrowstyle='->'))

plt.title("Newton's Method for f(x) = x² - 4")
plt.xlabel('x')
plt.ylabel('f(x)')
plt.legend()
plt.xlim(-1, 3)
plt.ylim(-5, 5)
plt.tight_layout()
plt.show()
```

## A Simple Example

Let's find the root of the function $f(x) = x^2 - 4$ using Newton's method. The derivative of $f(x)$ is $f'(x) = 2x$.

1. Choose an initial guess $x_0 = 1$.
2. Compute $f(x_0) = 1^2 - 4 = -3$ and $f'(x_0) = 2 \times 1 = 2$.
3. Compute the next approximation:

   $$
   x_1 = x_0 - \frac{f(x_0)}{f'(x_0)} = 1 - \frac{-3}{2} = 1 + \frac{3}{2} = 2.5
   $$

4. For the next iteration:
   $$
   f(x_1) = (2.5)^2 - 4 = 6.25 - 4 = 2.25
   $$
   
   $$
   f'(x_1) = 2 \times 2.5 = 5
   $$
   
   $$
   x_2 = x_1 - \frac{f(x_1)}{f'(x_1)} = 2.5 - \frac{2.25}{5} = 2.5 - 0.45 = 2.05
   $$

5. For the third iteration:
   
   $$
   f(x_2) = (2.05)^2 - 4 = 4.2025 - 4 = 0.2025
   $$
   
   $$
   f'(x_2) = 2 \times 2.05 = 4.1
   $$
   
   $$
   x_3 = x_2 - \frac{f(x_2)}{f'(x_2)} = 2.05 - \frac{0.2025}{4.1} \approx 2.05 - 0.049 \approx 2.001
   $$

As we can see, we're quickly approaching the exact root $x = 2$.

Let's run the algorithm and watch it converge:

```{python}
#| label: tbl-newton-convergence
#| tbl-cap: "Convergence of Newton's Method"
import pandas as pd

def newton_step(f, f_prime, x):
    fx = f(x)
    fpx = f_prime(x)
    return x - fx/fpx, fx, fpx

# Define our function and its derivative
def f(x):
    return x**2 - 4

def f_prime(x):
    return 2*x

# Set up initial conditions
x0 = 1
tolerance = 1e-10
max_iterations = 10

# Run Newton's method
x = x0
data = []

for i in range(max_iterations):
    fx = f(x)
    fpx = f_prime(x)
    
    data.append({
        'Iteration': i,
        'x_n': x,
        'f(x_n)': fx,
        'f\'(x_n)': fpx,
        '|f(x_n)|': abs(fx)
    })
    
    if abs(fx) < tolerance:
        break
        
    x = x - fx/fpx

# Display results
df = pd.DataFrame(data)
df.style.format({
    'x_n': '{:.10f}',
    'f(x_n)': '{:.10f}',
    'f\'(x_n)': '{:.10f}',
    '|f(x_n)|': '{:.10e}'
})
```

As we can see, Newton's method converges quadratically, which means the number of correct digits roughly doubles with each iteration. This makes it extremely efficient when it works well.

## Python Implementation

Here's a general implementation of Newton's method in Python:

```{python}
def newton_method(f, f_prime, x0, tol=1e-10, max_iter=100):
    """
    Implements Newton's method for finding roots of a function.
    
    Parameters:
    -----------
    f : callable
        The function whose root we want to find.
    f_prime : callable
        The derivative of the function.
    x0 : float
        Initial guess for the root.
    tol : float, optional
        Tolerance for convergence (default: 1e-10).
    max_iter : int, optional
        Maximum number of iterations (default: 100).
        
    Returns:
    --------
    float
        The approximate root of the function.
        
    Raises:
    -------
    ValueError
        If the derivative is zero at some point or if the method
        does not converge within max_iter iterations.
    """
    x = x0
    
    for i in range(max_iter):
        fx = f(x)
        # Check if we've found the root within tolerance
        if abs(fx) < tol:
            return x
        
        # Calculate derivative and check if it's zero
        dfx = f_prime(x)
        if dfx == 0:
            raise ValueError("Derivative of f(x) is zero. Cannot continue.")
        
        # Newton's update step
        x_next = x - fx / dfx
        
        # Optional: check if we're making significant progress
        if abs(x_next - x) < tol:
            return x_next
            
        x = x_next
    
    # If we get here, we've used all iterations without converging
    raise ValueError(f"Newton's method did not converge after {max_iter} iterations.")
```

Let's test our implementation with a few examples:

```{python}
import numpy as np

# Example 1: f(x) = x^2 - 4
f1 = lambda x: x**2 - 4
f1_prime = lambda x: 2*x

# Example 2: f(x) = sin(x)
f2 = lambda x: np.sin(x)
f2_prime = lambda x: np.cos(x)

# Example 3: f(x) = e^x - 3
f3 = lambda x: np.exp(x) - 3
f3_prime = lambda x: np.exp(x)

try:
    root1 = newton_method(f1, f1_prime, 1)
    root2 = newton_method(f2, f2_prime, 2)  # Finding π
    root3 = newton_method(f3, f3_prime, 0)
    
    print(f"Root of x^2 - 4 = 0: {root1}")
    print(f"Root of sin(x) = 0: {root2}")
    print(f"Root of e^x - 3 = 0: {root3}")
    
except ValueError as e:
    print(f"Error: {e}")
```

## Limitations and Considerations

Newton's method is powerful, but it has some limitations:

1. **Derivative Requirement**: We need to know the derivative of the function, which might be complicated or unavailable.
2. **Division by Zero**: If the derivative is zero at any iteration, the method fails.
3. **Convergence Issues**: 
   - The method may not converge for all functions or initial guesses
   - It can oscillate between values or diverge to infinity
   - For functions with multiple roots, which root is found depends on the initial guess
4. **Multiple Dimensions**: For functions of multiple variables, Newton's method becomes more complex, requiring the Jacobian matrix.

## Real-World Applications

Newton's method is used in various fields:

- **Numerical Analysis**: Finding zeros of complex functions
- **Optimization**: Finding extrema of functions (by locating zeros of the derivative)
- **Machine Learning**: Used in optimization algorithms like Newton-Raphson for logistic regression
- **Physics**: Solving nonlinear equations in mechanics, electrodynamics, etc.
- **Engineering**: Circuit analysis, structural mechanics
- **Computer Graphics**: Ray tracing and intersection calculations

## Appendix: Tangent Line Equation {.appendix}

The equation of the tangent line to a function $f(x)$ at a point $x_0$ is given by:

$$y = f'(x_0)(x - x_0) + f(x_0)$$

where $f'(x_0)$ is the derivative of the function at $x_0$.

This construction is based on three transformations of the $y = x$ line:

1. Scale the linear function by the derivative $f'(x_0)$
2. Shift the line horizontally by $x_0$
3. Shift the line vertically by $f(x_0)$

## Further Reading {.appendix}

- For multidimensional problems, look into the multivariate Newton-Raphson method
- For cases where derivatives are difficult to compute, consider Secant Method or Broyden's Method
- To improve convergence for problematic functions, explore damped Newton methods
